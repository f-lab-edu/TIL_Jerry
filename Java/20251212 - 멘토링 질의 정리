[서두]
- 역시 이어서 멘토링의 질의를 정리하면서 또 탐구하는 시간을 가져볼까한다

[질문]
- 메인 메서드의 의미에 대해서 생각해본적 있냐
모든 언어가 첫 시작점, 엔트리 포인트가 있다. 그래야 디버깅을 등을 할 때 어디서부터 시작해야하는지 알 수 있기 때문이다.
static을 사용하는 이유는 처음에 자바 실행하자말자 객체를 만들 수 없기 때문에 최소한 객체 생성 없이 시작할 수 있는 함수 하나가 있어야하기에 그렇다.
또한 이름이 Main으로 되어 있어야 JVM이 그 함수를 강제로 호출해주기에 이름은 고정되어있다.

- 클래스 객체하고 클래스하고 어떤 차이가 있는지?
객체를 활용해야 클래스에 접근할 수 있다. 객체는 파일이 없으며 실행 후 메모리에 생기는 것.

- 객체가 가져올 수 있는게, 상태말고 또 뭘 가지고 올 수 있느냐?
메서드. 대표적이다. 또한 어떤 상태값을 가지고 있다면 이게 책임을 가지고 있다라고 정의할 수 있는데, 이게 포인트다. 책임을 어디까지 갖고 있게하는지, 책임이 많으면 객체가 무겁다 등의 표현을 할 수 있으며
설계시 너무 많은 책임은 관심사를 분리한다라는 표현으로 자르는 부분이기도 하다.
+ 보통 객체가 퍼블릭으로 외부에서 호출할 수 있는 메서드, 이걸 노출된 인터페이스라고 부른다. 

- 아스키 코드란?
65가 대문자 a, 97이 소문자 a 
기본적인 건 외우고 있으면 좋다. 나중에 헥사로 되어있는 덤프 같은 거 떴을 때 쉽게 찾을 수 있다.

- 원시 타입과 참조 타입은 우리가 따로 초기화 시키지 않는다면 기본 값을 어떤 것을 가지는가?
참조 타입은 기본적으로 null
원시타입은, int라면 0, boolean처럼 0을 못 가진다면 false를 기본 값으로 가진다.

- 그렇다면 int를 활용하여 메서드의 파라미터를 넘겨받는 것과 Integer를 활용하여 넘겨받는 것은 또 어떤 차이가 있을까
int는 null이 될 수 없으니까 null 체크 안 해도 된다. 레퍼런스 타입은 널 체크해야한다.
또한 메모리 차이도 크다. 원시 타입은 딱 4바이트만 쓰게되는데 반해 Integer는 16 바이트인가 쓰게 된다.

- 부동 소수점에서, 금전 계산 등은 부동 소수점으로 하지말라는 얘기를 들어본 적이 있나?
기본적으로 float, double 등의 기본 부동소수점 타입들은 계산이 안 맞는다. 컴퓨터는 2진수로 표현해야하고, 사람은 10진수를 원해서.
그래서 조금씩 오차가 누적된다. 보통은 Big Decimal 같은 걸 쓴다. 근데 좀 많이 무겁고 메모리도 많이 먹어서 성능 이슈가 있을 때에는 앱실론 같은 걸로 소수점 자릿수 정의하고 쓴다.

- 앱실론에 대해서 들어봤는가?
앱실론은 실수 계산에서 여기까지는 같은 값으로 봐도 된다라고 잡아두는 아주 작은 기준점.
예를 들어 우리 프로젝트에서는 부동 소수점 다섯째짜리 이하에서 반올림한다, 이런 식의 규약을 의미함.
상수 값을 하나 만드는 것이라고 생각하면 좋다.
+ float을 안 쓰는 건 아니다. LLM 모델 구성 다 소수점으로 계산한다. 구글 밋 등에서 쓸 수 있는 3D 그래픽 등 모두 소수점으로 계산하는거다. 

- CPU와 GPU의 차이에 대해서 아는지?
게임때문에 사용하기 시작한게  GPU. 3D 게임이 나오기 시작하면서 렌더링을 해야하는데 모두 소수점으로 하다보니 CPU로 계산이 안 돼는 이슈. CPU는 정수 계산만 가능. 안에 서브 유닛같은 부동 소수점을 따로 계산해주는 서브 유닛이 있지만 성능이 별로.
그래서 GPU는 부동 소수점만 전문으로 계산하는 칩. 그래서 렌더링 같은 소수점 계산이 필요한 부분은 GPU를 붙여주는 것.
마침 모델 연산도 소수점으로 하는 부분이 있다보니 GPU를 사용하게 된 것.

- 오버플로우와 언더플로우 경험해 본 적 있으시냐
int[] 배열을 예시로 든다면, 이게 왜 특정 수를 넘어가면 마이너스가 나오는지 아느냐
이진수로 표현할 때 2의 보수 방식을 쓰는데 이게 부호 비트를 사용한다. 맨 앞 최상위 한 비트가 부호 비트다.
양수는 부호비트가 0, 음수는 1이다. 
예를 들면, 8비트가 있다. 원래 이진수로 256까지 표현이 가능해야한다. 근데 부호 비트 때문에 7비트만 쓸 수 있으니 127까지 표현이 가능하다. 
여기서 1을 더하면 부호비트가 올라가며 -128이 되는 원리이다. 
+ 이런 정보를 알게 된다면, 2의 보수에 대해서 이해를 하게 된다면 디버깅시 용이해진다.

- 단락 평가, 단축 평가에 대해서 들어본 적 있나
AND 연산에서 만약 앞이 거짓이면 뒤는 평가할 필요가 없으니 생략한다. 컴파일러가 최적화를 한다. 
반대로 앞에가 참이면 뒤에는 안 본다.

- 그렇다면 단점이 뭐가 있을까? 
만약 메서드를 AND 연산으로 사용한다고 가정하면 뒤에 메서드가 실행 안되는 이슈가 있을 수 있다.
updateA && updateB 라고 한다면 경우에 따라서 B 메서드가 업데이트가 안되는 케이스가 생길 수 있다.
A = updateA
B = updateB
if(A && B)  이렇게 하면 정상적으로 돈다

- 만약 엔퍼센트 하나만 있는 비트연산이라면 어떤 결과가 나오나?
비트 연산은 이런 단축, 단락 평가를 진행하지 않는다
비트 연산은 뒤에 있는 업데이트는 무조건 실행된다.
최적화가 없다는 얘기.

-비트 마스킹, 비트 플래그 들어보신 적 있냐
비트 플래그란, 어떤 값 등이 포함되어있는지를 확인 등을 할 떄 활용이 가능한 연산. 
메모리의 최소 크기 단위인 1바이트의 개별 비트를 비트 플래그라고 한다.
메모리 공간 절약이 장점.
비트 마스크란 플래그의 비트를 조작하거나 검사할 떄 사용하는 숫자를 비트 마스크라고 부른다.
특정 플래그를 키거나 끄고 확인하는 것 등의 활용이 그 예시다.


[인사이트]
•  프리미티브 타입은 널(null)을 가질 수 없고, 레퍼런스 타입은 널을 기본값으로 갖는다. 이로 인해 메서드 파라미터 처리, 메모리 사용, 예외 처리에 차이가 발생한다.
•  부동 소수점 연산은 이진수 표현의 한계로 인해 오차가 발생하며, 금전 계산에는 빅데시멀 등 정밀한 타입을 사용해야 한다.
•  2의 보수 표현 방식과 부호 비트 개념을 이해하면 오버플로우/언더플로우 현상을 예측하고 디버깅에 활용할 수 있다.
•  단락 평가(Short-circuit evaluation)는 효율적이지만, 함수 호출이 생략되어 의도치 않은 사이드 이펙트가 발생할 수 있다.
•  비트 연산자는 단락 평가 없이 모든 피연산자를 평가하며, 비트 플래그/마스킹을 통해 메모리와 네트워크 트래픽을 최적화할 수 있다.
•  비트 플래그는 여러 불리언 상태를 한 바이트로 관리할 수 있어 대규모 데이터 처리에 유리하다.
•  코딩 컨벤션(네이밍 규칙)은 협업과 유지보수에 필수적이며, 파스칼/카멜/스네이크 케이스 등 다양한 표준이 존재한다.
•  엔트리 포인트(main 메서드)는 프로그램 실행의 시작점이며, static이어야 객체 생성 없이 호출 가능하다.
•  TCP/IP 소켓 추상화는 OS별 차이를 감추고, 프레임워크(예: Netty)가 내부적으로 최적화된 방식을 선택한다.
•  CPU는 정수 연산에, GPU는 대규모 부동 소수점 연산에 특화되어 있다.
•  객체의 책임 분리는 설계의 핵심이며, 관심사 분리를 통해 유지보수성과 확장성을 높일 수 있다.
